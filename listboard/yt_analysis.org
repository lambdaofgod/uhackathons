#+title: Yt Analysis

#+BEGIN_SRC python :session yt_analysis.org  :exports both
import pandas as pd
import glob

glob.glob("data/*")
#+END_SRC

#+BEGIN_SRC python :session yt_analysis.org  :exports both :async
playlist_df = pd.read_json("data/playlist_info.jsonl", lines=True, orient="records")
#+END_SRC

#+RESULTS:
: None

#+BEGIN_SRC python :session yt_analysis.org  :exports both
playlist_df[["title", "Playlist", "description"]].head()
#+END_SRC

#+BEGIN_SRC python :session yt_analysis.org  :exports both
playlist_df["Playlist"].value_counts().head(10)
#+END_SRC

#+BEGIN_SRC python :session yt_analysis.org  :exports both
# Import necessary libraries
from listboard.cluster_analyzer import TextClusterAnalyzer
from listboard.util import SentenceTransformerEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
import numpy as np
#+END_SRC

#+BEGIN_SRC python :session yt_analysis.org  :exports both :async
# Create feature extraction with Sentence Transformer using MPNet
sentence_encoder = SentenceTransformerEncoder(
    model_name='all-mpnet-base-v2',  # More powerful model than MiniLM
    batch_size=16,  # Smaller batch size as MPNet is larger
    show_progress=True
)

# Dimensionality reduction with PCA
# K-means clustering
n_clusters = 20
kmeans = KMeans(n_clusters=n_clusters, random_state=42)

# Create TextClusterAnalyzer with sentence transformer
cluster_analyzer = TextClusterAnalyzer.create(
    df=playlist_df,
    text_columns=["title", "description"],
    clusterer=kmeans,
    feature_extractor=sentence_encoder,
    text_joiner="\n"
)
#+END_SRC

#+RESULTS:
: None

#+BEGIN_SRC python :session yt_analysis.org  :exports both :async
features = cluster_analyzer.text_clusterer_result.features
labels = cluster_analyzer.text_clusterer_result.labels
#+END_SRC

#+RESULTS:
: None

#+BEGIN_SRC python :session yt_analysis.org  :exports both :async :results output
cluster_df = playlist_df.copy()
cluster_df['cluster'] = labels

# Get representative examples for each cluster using the new method
cluster_examples = cluster_analyzer.get_cluster_examples(n_per_cluster=3)

# Show the most common playlists in each cluster
for i in range(n_clusters):
    print("#" * 50)
    print(f"\nCluster {i} - Top Playlists:")
    print(cluster_df[cluster_df['cluster'] == i]['Playlist'].value_counts().head(5))

    # Show representative examples from this cluster
    print(f"\nCluster {i} - Representative Descriptions (closest to centroid):")
    examples = cluster_examples[cluster_examples['cluster_id'] == i]

    for _, row in examples.iterrows():
        example = row['extracted_text']
        title = row['title']
        playlist = row['Playlist']
        print(f"- [{playlist}] {title}")
        print(f"  {example[:100]}..." if len(example) > 100 else f"  {example}")

    print("#" * 50)
#+END_SRC

* Youtube playlists via yt-dlp
:PROPERTIES:
:CREATED:  <2025-07-21 Mon> [20:35]
:END:


#+BEGIN_SRC python :session yt_analysis.org  :exports both
from listboard import youtube
#+END_SRC

#+RESULTS:
: None

#+BEGIN_SRC python :session yt_analysis.org  :exports both :async
playlists = youtube.get_current_user_playlists(youtube.AuthArgs(browser="firefox"))
#+END_SRC

#+RESULTS:
: None

#+BEGIN_SRC python :session yt_analysis.org  :exports both
playlists[1].playlist_name
#+END_SRC

#+RESULTS:
: Watch Later

#+BEGIN_SRC python :session yt_analysis.org  :exports both :async
import time

start_time = time.time()
watch_later_videos = playlists[1].get_videos()
end_time = time.time()

print(f"Time taken to fetch 'Watch Later' videos: {end_time - start_time:.2f} seconds")
#+END_SRC

#+RESULTS:
: /var/folders/t7/9zd9yqf17_zbfq2hwm8tv9ym0000gn/T/babel-CgwgSO/python-yHh5Fj

#+BEGIN_SRC python :session yt_analysis.org  :exports both
watch_later_videos.shape
#+END_SRC

#+RESULTS:
| 100 | 9 |

#+BEGIN_SRC python :session yt_analysis.org  :exports both
watch_later_videos["description"]
#+END_SRC

#+RESULTS:
#+begin_example
0     Can I beat this Challenging Origin in Stellari...
1     AI models are getting tasked to do increasingl...
2     Bad designs are still bad. AI doesnâ€™t make it ...
3     Today, we learn how to build secure generative...
4     35% off discount code from our upcoming course...
                            ...
95    Looking to grow your business online? Odoo is ...
96    ðŸ’»Make your life easier and try Dashlane on you...
97    The simple idea of a single possibility of the...
98    #history #yugoslavia #balkan \nGet InVideo AI ...
99    Subskrybuj kanaÅ‚ TVN24 i bÄ…dÅº na bieÅ¼Ä…co: http...
Name: description, Length: 100, dtype: object
#+end_example

#+BEGIN_SRC python :session yt_analysis.org  :exports both
watch_later_videos[["title", "description"]].iloc[:50]
#+END_SRC

#+RESULTS:
: Empty DataFrame
: Columns: [title, description]
: Index: []
